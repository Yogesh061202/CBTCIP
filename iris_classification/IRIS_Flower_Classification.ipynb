# Install required libraries
!pip install pandas matplotlib seaborn scikit-learn mlxtend
***Import the improtant librabries required for loading the iris dataset, preprocessing the data, training classification models, evaluating their performance, and visualizing the results.***

# Import necessary libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import pickle
from mlxtend.plotting import plot_decision_regions


***● Load the required Dataset***
# Load the iris dataset
iris = pd.read_csv('Iris.csv')
print("\nDataset preview:\n", iris.head())


# Explore the dataset
print("\nDataset information:\n", iris.info())
print("\nDescriptive statistics:\n", iris.describe())

***●Visualizizing the Dataset***

# Visualize the dataset
sns.pairplot(iris, hue='Species')
plt.show()

# Split features and target
X = iris.drop('Species', axis=1)
y = iris['Species']

# Encode target variable
le = LabelEncoder()
y = le.fit_transform(y)

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)


***●Evaluate Model Performance***

# Function to evaluate model performance
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print("Accuracy:", acc)
    print("Classification Report:\n", classification_report(y_test, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# **LOGISTIC REGRESSION -**

# Logistic Regression
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)
print("\nLogistic Regression:")
evaluate_model(log_reg, X_test, y_test)
# **DECISION TREE-**

# Decision Tree
dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
print("\nDecision Tree:")
evaluate_model(dt, X_test, y_test)

# **RANDOM FOREST**

# Random Forest
rf = RandomForestClassifier()
rf.fit(X_train, y_train)
print("\nRandom Forest:")
evaluate_model(rf, X_test, y_test)

# **SUPPORT VECTOR MACHINE**

# Support Vector Machine
svm = SVC()
svm.fit(X_train, y_train)
print("\nSupport Vector Machine:")
evaluate_model(svm, X_test, y_test)
# **K-NEAREST NEIGHBORS**
# K-Nearest Neighbors
knn = KNeighborsClassifier()
knn.fit(X_train, y_train)
print("\nK-Nearest Neighbors:")
evaluate_model(knn, X_test, y_test)

***●Selecting The Best Model***

# Select the best model (e.g., Random Forest)
best_model = rf

# Select features for visualization
features = ['PetalLengthCm', 'PetalWidthCm']
X_vis = iris[features]
X_vis_train, X_vis_test, y_vis_train, y_vis_test = train_test_split(X_vis, y, test_size=0.2, random_state=42)

# Fit the best model on the selected features
best_model.fit(X_vis_train, y_vis_train)

# Visualize decision boundaries
plot_decision_regions(X_vis_test.values, y_vis_test, clf=best_model, filler_feature_values={
                      'SepalLengthCm': iris['SepalLengthCm'].mean(),
                      'SepalWidthCm': iris['SepalWidthCm'].mean()},
                      legend=2)
plt.show()

# Feature importances
print("\nFeature Importances:")
for feature, importance in zip(X.columns, best_model.feature_importances_):
    print(f"{feature}: {importance:.2f}")

# Save the trained model
with open('iris_classifier.pkl', 'wb') as f:
    pickle.dump(best_model, f)

print("\nModel saved as 'iris_classifier.pkl'")
**Conclusion**:
In this project, we trained and evaluated several machine learning models for classifying iris flowers
into three species based on their sepal and petal measurements. The Random Forest model emerged as
the best performer, achieving an accuracy of 100% on the test set.

**Potential improvements and future work:**
- Explore more feature engineering techniques
- Tune hyperparameters of the models
- Try ensemble methods or stacking
- Collect more data or use data augmentation techniques
